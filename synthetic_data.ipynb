{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir= 'data', split= 'train', track= 'a', language= 'ptbr'):\n",
    "    \n",
    "    archive = language + '.csv' if split == 'train' else language + '_' + track + '.csv'\n",
    "\n",
    "    path = f'{dir}/{split}/track_{track}/{archive}'\n",
    "    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos contemplar, primeiramente, a geração de dados sintéticos para a track A, onde temos uma classificação binária de emoções.\n",
    "\n",
    "Seguiremos a abordagem do artigo: https://aclanthology.org/2024.acl-long.120.pdf\n",
    "\n",
    "\n",
    "Focaremos na variabilidade desses dados, e uma abordagem few shot, iremos variar na seguinte medida:\n",
    "\n",
    "\n",
    "    - Emoções (faremos isso dinâmico em função do dataset (a probabilidade será proporcional a quantidade de amostras))\n",
    "    - Tamanho do tweet (amostrados em função dos tamanhos reais)\n",
    "    - Intensidade do sentimento (leve, moderado, forte)\n",
    "\n",
    "\n",
    "\n",
    "Os dados serão retornados em formato de JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n",
    "\n",
    "'''Vamos estratificar o dataset, tendo somente uma coluna de emoções'''\n",
    "\n",
    "emotion_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
    "df['labels'] = df[emotion_columns].apply(\n",
    "    lambda row: ' '.join([col for col, val in row.items() if val == 1]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df['labels'] = df['labels'].apply(\n",
    "    lambda x: 'Neutral' if x == '' else x\n",
    ")\n",
    "\n",
    "df = df.drop(columns=emotion_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Médio': 811, 'Curto': 884, 'Longo': 531},\n",
       " {'Sadness': 171,\n",
       "  'Joy': 494,\n",
       "  'Neutral': 632,\n",
       "  'Anger': 475,\n",
       "  'Anger Sadness': 90,\n",
       "  'Surprise': 61,\n",
       "  'Disgust': 8,\n",
       "  'Anger Surprise': 36,\n",
       "  'Joy Surprise': 32,\n",
       "  'Fear': 52,\n",
       "  'Anger Sadness Surprise': 3,\n",
       "  'Anger Fear': 17,\n",
       "  'Anger Disgust': 49,\n",
       "  'Anger Joy': 24,\n",
       "  'Anger Disgust Sadness': 9,\n",
       "  'Fear Sadness': 13,\n",
       "  'Fear Surprise': 8,\n",
       "  'Disgust Sadness': 4,\n",
       "  'Anger Joy Surprise': 2,\n",
       "  'Joy Sadness': 20,\n",
       "  'Anger Joy Sadness': 1,\n",
       "  'Anger Fear Sadness': 5,\n",
       "  'Anger Disgust Fear Sadness': 1,\n",
       "  'Fear Joy': 6,\n",
       "  'Anger Fear Surprise': 5,\n",
       "  'Fear Joy Sadness': 1,\n",
       "  'Disgust Surprise': 1,\n",
       "  'Disgust Sadness Surprise': 1,\n",
       "  'Sadness Surprise': 2,\n",
       "  'Anger Disgust Surprise': 1,\n",
       "  'Joy Sadness Surprise': 1,\n",
       "  'Disgust Fear': 1})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(length):\n",
    "        if length <= 11:\n",
    "            return \"Curto\"\n",
    "        elif length <= 26:\n",
    "            return \"Médio\"\n",
    "        elif length >= 26:\n",
    "            return \"Longo\"\n",
    "\n",
    "\n",
    "category_counts = dict(Counter(df['text'].apply(lambda x: categorize(len(x.split())))))\n",
    "emotion_counts = dict(Counter(df['labels']))\n",
    "\n",
    "category_counts, emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amostra_categoria_e_emocao(label_dict, category_dict):\n",
    "    \"\"\"\n",
    "    Amostra simultaneamente uma emoção e uma categoria, com probabilidade inversa às contagens em cada dicionário.\n",
    "    Atualiza as contagens após a amostragem.\n",
    "\n",
    "    Args:\n",
    "    - label_dict (dict): Dicionário de emoções e suas contagens.\n",
    "    - category_dict (dict): Dicionário de categorias e suas contagens.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Emoção e categoria amostradas.\n",
    "    \"\"\"\n",
    "    inverse_weights_labels = {label: 1 / count for label, count in label_dict.items() if count > 0}\n",
    "    total_weight_labels = sum(inverse_weights_labels.values())\n",
    "    probabilities_labels = {label: weight / total_weight_labels for label, weight in inverse_weights_labels.items()}\n",
    "    labels = list(probabilities_labels.keys())\n",
    "    weights_labels = list(probabilities_labels.values())\n",
    "    sampled_label = random.choices(labels, weights=weights_labels, k=1)[0]\n",
    "    label_dict[sampled_label] += 1\n",
    "\n",
    "    inverse_weights_categories = {category: 1 / count for category, count in category_dict.items() if count > 0}\n",
    "    total_weight_categories = sum(inverse_weights_categories.values())\n",
    "    probabilities_categories = {category: weight / total_weight_categories for category, weight in inverse_weights_categories.items()}\n",
    "    categories = list(probabilities_categories.keys())\n",
    "    weights_categories = list(probabilities_categories.values())\n",
    "    sampled_category = random.choices(categories, weights=weights_categories, k=1)[0]\n",
    "    category_dict[sampled_category] += 1\n",
    "    \n",
    "    for emotion in intensity_counts:\n",
    "        \n",
    "    \n",
    "\n",
    "    return sampled_label, sampled_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sadness Surprise', 'Longo')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amostra_categoria_e_emocao(emotion_counts, category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptbr_train_track_a_00001</td>\n",
       "      <td>minha vó me disse que era frango e eu comi, ti...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptbr_train_track_a_00002</td>\n",
       "      <td>Está e a nossa deputada Benedita linda guerrei...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptbr_train_track_a_00003</td>\n",
       "      <td>só falta as roupas kkkkkkkkkkk</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptbr_train_track_a_00004</td>\n",
       "      <td>Eu tmb. Comecei a sair de casa agora (fui pela...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptbr_train_track_a_00005</td>\n",
       "      <td>Peço a Deus que nossos dirigentes tenham realm...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>ptbr_train_track_a_02222</td>\n",
       "      <td>Eu acho que o CAP vai surpreender hein.</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>ptbr_train_track_a_02223</td>\n",
       "      <td>23:59 - Lula sabia de toda a corrupção no seu ...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>ptbr_train_track_a_02224</td>\n",
       "      <td>O Brasil precisa URGENTE de pessoas sérias e c...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>ptbr_train_track_a_02225</td>\n",
       "      <td>Sera que só eu acho que ta passando da hora de...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>ptbr_train_track_a_02226</td>\n",
       "      <td>falta só 2 porra</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0     ptbr_train_track_a_00001   \n",
       "1     ptbr_train_track_a_00002   \n",
       "2     ptbr_train_track_a_00003   \n",
       "3     ptbr_train_track_a_00004   \n",
       "4     ptbr_train_track_a_00005   \n",
       "...                        ...   \n",
       "2221  ptbr_train_track_a_02222   \n",
       "2222  ptbr_train_track_a_02223   \n",
       "2223  ptbr_train_track_a_02224   \n",
       "2224  ptbr_train_track_a_02225   \n",
       "2225  ptbr_train_track_a_02226   \n",
       "\n",
       "                                                   text    labels  \n",
       "0     minha vó me disse que era frango e eu comi, ti...   Sadness  \n",
       "1     Está e a nossa deputada Benedita linda guerrei...       Joy  \n",
       "2                        só falta as roupas kkkkkkkkkkk       Joy  \n",
       "3     Eu tmb. Comecei a sair de casa agora (fui pela...   Sadness  \n",
       "4     Peço a Deus que nossos dirigentes tenham realm...   Neutral  \n",
       "...                                                 ...       ...  \n",
       "2221            Eu acho que o CAP vai surpreender hein.  Surprise  \n",
       "2222  23:59 - Lula sabia de toda a corrupção no seu ...     Anger  \n",
       "2223  O Brasil precisa URGENTE de pessoas sérias e c...     Anger  \n",
       "2224  Sera que só eu acho que ta passando da hora de...     Anger  \n",
       "2225                                   falta só 2 porra       Joy  \n",
       "\n",
       "[2226 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anger': {0: 66.76, 1: 21.61, 2: 10.51, 3: 1.12},\n",
       " 'Disgust': {0: 96.18, 1: 3.41, 2: 0.31, 3: 0.09},\n",
       " 'Fear': {0: 94.74, 1: 4.0, 2: 1.12, 3: 0.13},\n",
       " 'Joy': {0: 73.63, 1: 13.12, 2: 12.35, 3: 0.9},\n",
       " 'Sadness': {0: 84.73, 1: 10.2, 2: 4.4, 3: 0.67},\n",
       " 'Surprise': {0: 92.59, 1: 5.75, 2: 1.35, 3: 0.31}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = get_data(track='b')\n",
    "intensity_counts = {emotion: (aux[emotion].value_counts(normalize=True) * 100).round(2).to_dict() for emotion in emotion_columns}\n",
    "intensity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoção: Anger\n",
      "Emoção: Disgust\n",
      "Emoção: Fear\n",
      "Emoção: Joy\n",
      "Emoção: Sadness\n",
      "Emoção: Surprise\n"
     ]
    }
   ],
   "source": [
    "for emotion in intensity_counts:\n",
    "    print(f'Emoção: {emotion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
