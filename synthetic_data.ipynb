{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir= 'data', split= 'train', track= 'a', language= 'ptbr'):\n",
    "    \n",
    "    archive = language + '.csv' if split == 'train' else language + '_' + track + '.csv'\n",
    "\n",
    "    path = f'{dir}/{split}/track_{track}/{archive}'\n",
    "    \n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abordagem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos contemplar, primeiramente, a geração de dados sintéticos para a track A, onde temos uma classificação binária de emoções.\n",
    "\n",
    "Seguiremos a abordagem do artigo: https://aclanthology.org/2024.acl-long.120.pdf\n",
    "\n",
    "\n",
    "Focaremos na variabilidade desses dados, e uma abordagem few shot, iremos variar na seguinte medida:\n",
    "\n",
    "\n",
    "    - Emoções (faremos isso dinâmico em função do dataset (a probabilidade será proporcional a quantidade de amostras))\n",
    "    - Tamanho do tweet (amostrados em função dos tamanhos reais)\n",
    "    - Intensidade do sentimento (leve, moderado, forte)\n",
    "\n",
    "\n",
    "\n",
    "Os dados serão retornados em formato de JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n",
    "\n",
    "'''Vamos estratificar o dataset, tendo somente uma coluna de emoções, isso nos ajuda, pois teremos agora também as \n",
    "combinações de emoções, posteriormente, vamos amostrar essas emoções para geração de novos dados, dando maior probabilidade a \n",
    "emoções ou combinações mais raras, atualizando isso de maneira dinâmica para atualizar a geração.'''\n",
    "\n",
    "\n",
    "emotion_columns = ['Anger', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
    "df['labels'] = df[emotion_columns].apply(\n",
    "    lambda row: ' '.join([col for col, val in row.items() if val == 1]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df['labels'] = df['labels'].apply(\n",
    "    lambda x: 'Neutral' if x == '' else x\n",
    ")\n",
    "\n",
    "df = df.drop(columns=emotion_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Médio': 811, 'Curto': 884, 'Longo': 531},\n",
       " {'Sadness': 171,\n",
       "  'Joy': 494,\n",
       "  'Neutral': 632,\n",
       "  'Anger': 475,\n",
       "  'Anger Sadness': 90,\n",
       "  'Surprise': 61,\n",
       "  'Disgust': 8,\n",
       "  'Anger Surprise': 36,\n",
       "  'Joy Surprise': 32,\n",
       "  'Fear': 52,\n",
       "  'Anger Sadness Surprise': 3,\n",
       "  'Anger Fear': 17,\n",
       "  'Anger Disgust': 49,\n",
       "  'Anger Joy': 24,\n",
       "  'Anger Disgust Sadness': 9,\n",
       "  'Fear Sadness': 13,\n",
       "  'Fear Surprise': 8,\n",
       "  'Disgust Sadness': 4,\n",
       "  'Anger Joy Surprise': 2,\n",
       "  'Joy Sadness': 20,\n",
       "  'Anger Joy Sadness': 1,\n",
       "  'Anger Fear Sadness': 5,\n",
       "  'Anger Disgust Fear Sadness': 1,\n",
       "  'Fear Joy': 6,\n",
       "  'Anger Fear Surprise': 5,\n",
       "  'Fear Joy Sadness': 1,\n",
       "  'Disgust Surprise': 1,\n",
       "  'Disgust Sadness Surprise': 1,\n",
       "  'Sadness Surprise': 2,\n",
       "  'Anger Disgust Surprise': 1,\n",
       "  'Joy Sadness Surprise': 1,\n",
       "  'Disgust Fear': 1},\n",
       " {'Anger': {'baixo': 65.0, 'moderado': 31.62, 'alto': 3.38},\n",
       "  'Disgust': {'baixo': 89.41, 'moderado': 8.24, 'alto': 2.35},\n",
       "  'Fear': {'baixo': 76.07, 'moderado': 21.37, 'alto': 2.56},\n",
       "  'Joy': {'baixo': 49.74, 'moderado': 46.85, 'alto': 3.41},\n",
       "  'Sadness': {'baixo': 66.76, 'moderado': 28.82, 'alto': 4.41},\n",
       "  'Surprise': {'baixo': 77.58, 'moderado': 18.18, 'alto': 4.24}})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(length):\n",
    "        if length <= 11:\n",
    "            return \"Curto\"\n",
    "        elif length <= 26:\n",
    "            return \"Médio\"\n",
    "        elif length >= 26:\n",
    "            return \"Longo\"\n",
    "        \n",
    "\n",
    "'''Gera a distribuição de tamanhos de texto'''\n",
    "category_counts = dict(Counter(df['text'].apply(lambda x: categorize(len(x.split())))))\n",
    "'''Gera a distribuição de emoções'''\n",
    "emotion_counts = dict(Counter(df['labels']))\n",
    "\n",
    "'''Gera uma distribuição da intensidade de emoções (baseados nos dados da track b)'''\n",
    "aux = get_data(track='b')\n",
    "intensity_counts = {\n",
    "    emotion: (aux[aux[emotion] > 0][emotion].value_counts(normalize=True) * 100).round(2).to_dict()\n",
    "    for emotion in emotion_columns\n",
    "}\n",
    "\n",
    "intensity_counts = {\n",
    "    emotion: {\n",
    "        \"baixo\": values.get(1, 0), \n",
    "        \"moderado\": values.get(2, 0),\n",
    "        \"alto\": values.get(3, 0)\n",
    "    }\n",
    "    for emotion, values in intensity_counts.items()\n",
    "}\n",
    "\n",
    "category_counts, emotion_counts, intensity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amostra_categoria_e_emocao(label_dict, category_dict, intensity_counts):\n",
    "    '''Amostraremos baseado no tamanhjo do texto, emoção e intensidade da emoção.\n",
    "    \n",
    "    Para o tamanho e emoção, temos um dicionario dinâmico, onde as probabilidades da amostragem de cada emoção mudam ao longo\n",
    "    do tempo, baseado na quantidade de vezes que cada emoção foi amostrada. Para a intensidade, faremos de maneira estática, visto que\n",
    "    dados menos comuns são dados extremos (emoção alta), o que é muito fácil de se identificar no caso da track A. Por isso, usaremos como\n",
    "    probabilidade a presença de cada intensidade em cada emoção nos dados da track b, adicionamos essa \"feature\" apenas para gerar mais \n",
    "    variabilidade.\n",
    "    '''\n",
    "    inverse_weights_labels = {label: 1 / count for label, count in label_dict.items() if count > 0}\n",
    "    total_weight_labels = sum(inverse_weights_labels.values())\n",
    "    probabilities_labels = {label: weight / total_weight_labels for label, weight in inverse_weights_labels.items()}\n",
    "    labels = list(probabilities_labels.keys())\n",
    "    weights_labels = list(probabilities_labels.values())\n",
    "    sampled_label = random.choices(labels, weights=weights_labels, k=1)[0]\n",
    "    label_dict[sampled_label] += 1\n",
    "\n",
    "    inverse_weights_categories = {category: 1 / count for category, count in category_dict.items() if count > 0}\n",
    "    total_weight_categories = sum(inverse_weights_categories.values())\n",
    "    probabilities_categories = {category: weight / total_weight_categories for category, weight in inverse_weights_categories.items()}\n",
    "    categories = list(probabilities_categories.keys())\n",
    "    weights_categories = list(probabilities_categories.values())\n",
    "    sampled_category = random.choices(categories, weights=weights_categories, k=1)[0]\n",
    "    category_dict[sampled_category] += 1\n",
    "            \n",
    "    intensity_parts = []\n",
    "    for emotion in intensity_counts:\n",
    "        if str(emotion) in sampled_label:\n",
    "            probabilities = intensity_counts[str(emotion)]\n",
    "            categories = list(probabilities.keys())\n",
    "            weights = list(probabilities.values())\n",
    "            intensity = random.choices(categories, weights=weights, k=1)[0]\n",
    "            intensity_parts.append(f\"{emotion}: {intensity}\")\n",
    "\n",
    "    intensity_emotion = \", \".join(intensity_parts) if intensity_parts else \"Nenhuma intensidade encontrada\"\n",
    "\n",
    "    return sampled_label, sampled_category, intensity_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Disgust Fear', 'Longo', 'Disgust: baixo, Fear: baixo')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amostra_categoria_e_emocao(emotion_counts, category_counts, intensity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptbr_train_track_a_00001</td>\n",
       "      <td>minha vó me disse que era frango e eu comi, ti...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptbr_train_track_a_00002</td>\n",
       "      <td>Está e a nossa deputada Benedita linda guerrei...</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptbr_train_track_a_00003</td>\n",
       "      <td>só falta as roupas kkkkkkkkkkk</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptbr_train_track_a_00004</td>\n",
       "      <td>Eu tmb. Comecei a sair de casa agora (fui pela...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptbr_train_track_a_00005</td>\n",
       "      <td>Peço a Deus que nossos dirigentes tenham realm...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>ptbr_train_track_a_02222</td>\n",
       "      <td>Eu acho que o CAP vai surpreender hein.</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>ptbr_train_track_a_02223</td>\n",
       "      <td>23:59 - Lula sabia de toda a corrupção no seu ...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>ptbr_train_track_a_02224</td>\n",
       "      <td>O Brasil precisa URGENTE de pessoas sérias e c...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>ptbr_train_track_a_02225</td>\n",
       "      <td>Sera que só eu acho que ta passando da hora de...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>ptbr_train_track_a_02226</td>\n",
       "      <td>falta só 2 porra</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0     ptbr_train_track_a_00001   \n",
       "1     ptbr_train_track_a_00002   \n",
       "2     ptbr_train_track_a_00003   \n",
       "3     ptbr_train_track_a_00004   \n",
       "4     ptbr_train_track_a_00005   \n",
       "...                        ...   \n",
       "2221  ptbr_train_track_a_02222   \n",
       "2222  ptbr_train_track_a_02223   \n",
       "2223  ptbr_train_track_a_02224   \n",
       "2224  ptbr_train_track_a_02225   \n",
       "2225  ptbr_train_track_a_02226   \n",
       "\n",
       "                                                   text    labels  \n",
       "0     minha vó me disse que era frango e eu comi, ti...   Sadness  \n",
       "1     Está e a nossa deputada Benedita linda guerrei...       Joy  \n",
       "2                        só falta as roupas kkkkkkkkkkk       Joy  \n",
       "3     Eu tmb. Comecei a sair de casa agora (fui pela...   Sadness  \n",
       "4     Peço a Deus que nossos dirigentes tenham realm...   Neutral  \n",
       "...                                                 ...       ...  \n",
       "2221            Eu acho que o CAP vai surpreender hein.  Surprise  \n",
       "2222  23:59 - Lula sabia de toda a corrupção no seu ...     Anger  \n",
       "2223  O Brasil precisa URGENTE de pessoas sérias e c...     Anger  \n",
       "2224  Sera que só eu acho que ta passando da hora de...     Anger  \n",
       "2225                                   falta só 2 porra       Joy  \n",
       "\n",
       "[2226 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: criar loop para geração dos dados\n",
    "#todo estruturar prompt\n",
    "#todo lidar com json de saída\n",
    "#todo salvar dados e subir no hf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
